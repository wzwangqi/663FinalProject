\documentclass[11pt]{article}

\usepackage{setspace}
\usepackage{graphicx}
\usepackage{url}
\usepackage{color}
\usepackage{bm}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{epstopdf}
\usepackage{array}
\usepackage{subfigure}
\marginparwidth 0pt
\oddsidemargin  0pt
\evensidemargin  0pt
\marginparsep 0pt

\topmargin 0pt
\textwidth   6.5 in
\textheight  8.5 in


\begin{document}

\title{ Spectral Clustering Implementation and Appliacation }
\author{Qi Wang ~~~ Hanqiu Xia}
\maketitle

\abstract{Spectral clustering is widely used in image segmentation. The main idea of spectral clustering is to use the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction and then perform clustering in fewer dimensions.  In this project, we investigated the normalized spectral decomposition algorithm from the paper "On Spectral Clustering: Analysis and an algorithm" by A. Ng, M. Jordan, and Y. Weiss [1]. Their algorithm improved upon the existing spectral clustering algorithm by resolving the issues of inconsistent algorithms of using eigenvectors as well as providing evidence of it resulting in a reasonable clustering. We implemented the algorithm using Python with considering both common and edge cases. We also optimized the Python codes by applying vectorization, Cython, and Just-In-Time compiling. Finally, we tested the algorithm on simulated and real datasets and compare the experimental results with those of k-means clustering to see if spectral clustering dramatically improves the results.}

\section{Background}
\section{Implementation}
\subsection{Algorithm for Spectral Clustering}
\subsection{Ideal Case }
\subsection{General Case}


\section{Testing}
\subsection{Unit  Test for Common Case}
\subsection{Unit Test for Edge Case}

\section{Optimization}

\subsection{Vectorization}
\subsection{Cython}
\subsection{JIT (Just-In-Time compiling) }

\subsection{Improvement result}


\section{Application and Comparison}
\subsection{Application on Simulated Data}

\subsection{Application on Real Data}
\subsection{Comparison of Sepctral clustering and K-means}



\section{Conclusion}

%\bibliographystyle{plain}
%\bibliography{bibliography}


\newpage
\begin{thebibliography}{9}



\bibitem{nips} 
A. Ng, M. Jordan, and Y. Weiss.
On Spectral Clustering: Analysis and an algorithm.
\textit{Advances in Neural Information Processing}.
Vol. 14, No. 2. (2001), pp. 849-856 

\end{thebibliography}



\end{document}